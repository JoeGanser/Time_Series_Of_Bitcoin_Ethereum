{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "# Short term Time Series forecasting of Bitcoin & Ethereum using ARIMA and Neural Net LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**Joe Ganser**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The objective of this blog post is to experiment with time series techniques as well as methods in signal/noise extraction to make a prediction on the prices of both bitcoin and ethereum in the last week of August 2017, using all the previous pricing data.\n",
    "\n",
    "In this short term price forecast, I am predicting the next day's price based upon all the prices leading upto it. Then on the next day, I am repeating this process again, once next day's price is received. Model techniques like this could be used for high frequency trading, not long term investing. This is NOT about predicting long term trends.\n",
    "\n",
    "Because I am only predicting the next day out, and I am extracting the signal from the noise and what the models ACTUALLY predict is the noise. The predicted noise is then plugged back into the signal function, and that turns into the measurable prediction. This concept is explained a little more below.\n",
    "\n",
    "Lets take a look at the pricing data upto this point so far;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"450\" frameborder=\"0\" scrolling=\"no\" src=\"bitcoin&ethereum_fullplots.html\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "full_plots = '<iframe width=\"900\" height=\"450\" frameborder=\"0\" scrolling=\"no\" src=\"bitcoin&ethereum_fullplots.html\"></iframe>'\n",
    "IPython.display.HTML(full_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**WORKFLOW** \n",
    "\n",
    "My process in making these models this is as follows:\n",
    "\n",
    "    1.Extract the signal from the noise (find stationarity via dickey fuller test)\n",
    "    2.Model the noise, and predict the noise for the next day (ARIMA and Neural nets)\n",
    "    3.Plug the predicted noise into the signal, calculating the price value for the next day\n",
    "    4.Compare the predicted price of the next day to the actual next day's price\n",
    "    5.Repeat steps 2 and 3 once when obtaining the actual price of the next day  (use a for loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### MODEL CHOICES: ARIMA & NEURAL NET RECURSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The model choice was done simply for comparitive experimental reasons, only because ARIMA and Neural Net LSTM can predict time series. Other techniques could be done to, but I just wanted to compare these out of curiosity. Their performance metrics were the cumulative root mean square error across all the days predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### ASSUMPTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "The assumption, which is validated, is that the exponential long term trend shall remain over the last few days of August of 2017. The assumption was made through the techniques of signal noise extraction which are explained below. I do NOT assume that the exponential trend will go on forever."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "#### MODEL PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "Here are the final results - the actual predictions of my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"650\" frameborder=\"0\" scrolling=\"no\" src=\"bitcoin_ethereum_prediction_plots.html\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_plots = '<iframe width=\"900\" height=\"650\" frameborder=\"0\" scrolling=\"no\" src=\"bitcoin_ethereum_prediction_plots.html\"></iframe>'\n",
    "IPython.display.HTML(prediction_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "**MODEL PERFORMANCE METRICS**\n",
    "\n",
    "So looking at these results, what were the model performance metrics? The performance metric I used to compare the results of the techniques was the summed root mean square error across all the days predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bitcoin RMSE</th>\n",
       "      <th>Ethereum RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARIMA</th>\n",
       "      <td>49.6777</td>\n",
       "      <td>9.73758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Net</th>\n",
       "      <td>42.2849</td>\n",
       "      <td>1.67000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Bitcoin RMSE  Ethereum RMSE\n",
       "ARIMA            49.6777        9.73758\n",
       "Neural Net       42.2849        1.67000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "metrics = pd.DataFrame({'Neural Net':[42.2849,1.67],'ARIMA':[49.6777,9.73758]}).transpose().rename(columns={0:'Bitcoin RMSE',1:'Ethereum RMSE'})\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the RMSE of the Neural Nets was lower in this case and was thus the better performing model. Of course that's not to make a general statement that Neural Nets is better than ARIMA, because there are many examples where Neural Net time series analysis may be a better choice.\n",
    "\n",
    "So how did I solve this problem? As mentioned above in the work flow description, the first step is to extract the signal from the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **EXTRACTING THE SIGNAL FROM THE NOISE USING THE AUGMENTED DICKEY FULLER TEST**\n",
    "\n",
    "![Signal_noise](Signal_noise.png)\n",
    "\n",
    "\n",
    "The augmented dickey fuller test is a statistical test to determine \"stationarity\". Stationarity occurs when a series of data is transformed into format which clearly identifies the signal and all we are left with is noise. More specifically, stationarity occurs when we put the time series data is put into it's correct inverse function. With outputs similar to a Z-test, the test tells us if the new format we have has clearly identified the signal within the data. The null hypothesis of the Dickey Fuller test is that the signal and noise are NOT decoupled. The strategy behind using this is that by extracting the signal, we model and predict the noise and plug those predictions back into the signal.\n",
    "\n",
    "**THE BEST FIT FUNCTION & IT'S INVERSE**\n",
    "\n",
    "Knowing the best fitting function is not enough to model the time series. What is needed is not only a best fit function, but that function's inverse as well. By putting the data of the time series into the inverse function, we can get the noise values. It's noise values that are put into the Dickey Fuller test.\n",
    "\n",
    "![INVERSE](InverseFunction.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    Extracting the signal from the noise can be summed into three steps\n",
    "    1. Find the a function similar to the time series data.\n",
    "    2. Find that function's inverse.\n",
    "    3. Plug the time series data into the inverse, and plug that transformed data set into the Dickey Fuller Test\n",
    "    *If we haven't rejected the null hypothesis in step 3 try step 1 over starting with a different function.\n",
    "\n",
    "\n",
    "By looking at the very first plot, we can see that the trend of the cryptocurrency prices are in some way exponential. Thus, I can hypothesize that the signal is exponential in form.\n",
    "\n",
    "![bitcoin_vs_exponential](bitprice_vs_exponential_curve.png)\n",
    "\n",
    "\n",
    "The actual function form that allowed me to seperate the signal from the noise was indeed *exponential in form* but not simply exponential. It was by using this function's inverse that I could pass the dickey fuller test.\n",
    "\n",
    "The actual function that worked was this:\n",
    "\n",
    "![Function](function.png)\n",
    "\n",
    "These function transformations worked with both the bitcoin & ethereum data.\n",
    "\n",
    "The code that puts the data into stationary form is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = (np.log(data['Price'])-np.log(data['Price'].shift())).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "Where the '.shift()' cooresponds to the day before.\n",
    "\n",
    "**FAILING AND THEN PASSING THE DICKEY FULLER TEST**\n",
    "\n",
    "In the tabs below you'll see the attempt at passing the Dickey Fuller test without perfmoring any transformation, and then (botton of each tab), the Dickey Fuller test is passed (meaning we can reject the null hypothesis, and the data is stationary.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"900\" height=\"700\" frameborder=\"0\" scrolling=\"no\" src=\"bitcoin&ethereum_dickey_fuller.html\"></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dickeyfuller = '<iframe width=\"900\" height=\"700\" frameborder=\"0\" scrolling=\"no\" src=\"bitcoin&ethereum_dickey_fuller.html\"></iframe>'\n",
    "IPython.display.HTML(dickeyfuller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I have clearly identified the stationary form of the time series. These stationary forms can be plugged into the models to predict the noise, and using the noise predictions we can plug those back into the signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL BUILDING & MAKING PREDICTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So the prediction steps are:**\n",
    "\n",
    "    1. Plug the noise into the model\n",
    "    2. Train the model on the history of the noise\n",
    "    3. Predict the noise of the next day\n",
    "    4. Plug the next day's predicted noise into the signal function.\n",
    "    5. Add the actual price of the next day to the price data set, transform it into stationarity and start again at step 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELLING WITH ARIMA**\n",
    "\n",
    "There are several steps to building an ARIMA model. ARIMA operates on three parameters. Based upon the plots of auto-correlation, partial auto-correlation and the amount of Bayesian information criterion we select these three parameters. Ofcourse, the end goal is to minimize the root mean squared error of the model.\n",
    "\n",
    "**AUTO CORRELATION & PARTIAL AUTOCORRELATION PLOTS **\n",
    "\n",
    "The plots of auto-correlation & partial auto-correlation for bitcoin & ethereums stationary formats were:\n",
    "![correlation](correlation_plots.png)\n",
    "\n",
    "Using these plots I can estimate the ARIMA parameters (p,q) of the parameters (p,q,d) for ARIMA models. Just by looking at the graphs it can be estimate that p & q are around no more than 7 each. After grid searching through lots of combinations it was found that **Bitcoins ARIMA parameters were (p=0,d=1,q=1)** and **Ethereum's ARIMA parameters were (p=2,d=0,q=0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "bitcoin =pd.read_csv('bitcoin.csv').drop('Unnamed: 0',axis=1)\n",
    "bitcoin['Date'] = pd.to_datetime(bitcoin['Date'])\n",
    "bitcoin.set_index('Date',inplace=True)\n",
    "bits_log_shift = (np.log(bitcoin['Price']) - np.log(bitcoin['Price']).shift()).dropna()\n",
    "ethereum = pd.read_csv('ethereum.csv').drop('Unnamed: 0',axis=1)\n",
    "ethereum['Date'] = pd.to_datetime(ethereum['Date'])\n",
    "ethereum.set_index('Date',inplace=True)\n",
    "eth_log_shift = (np.log(ethereum['Price']) - np.log(ethereum['Price']).shift()).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here is the ARIMA model code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA bitcoin predictions\n",
      "ARIMA Root Mean Squared Error:  3.898537928223503\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Predicted with ARIMA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>4318.35</td>\n",
       "      <td>4321.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>4364.41</td>\n",
       "      <td>4368.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>4352.30</td>\n",
       "      <td>4356.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>4345.75</td>\n",
       "      <td>4349.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>4390.31</td>\n",
       "      <td>4394.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>4597.31</td>\n",
       "      <td>4601.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>4583.02</td>\n",
       "      <td>4587.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price  Predicted with ARIMA\n",
       "2017-08-23  4318.35               4321.92\n",
       "2017-08-24  4364.41               4368.25\n",
       "2017-08-25  4352.30               4356.23\n",
       "2017-08-26  4345.75               4349.69\n",
       "2017-08-27  4390.31               4394.20\n",
       "2017-08-28  4597.31               4601.04\n",
       "2017-08-29  4583.02               4587.37"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ARIMA_predictions(original_series,stationary_series,parameters, days_out):\n",
    "    # Here we predict the noise\n",
    "    train = stationary_series[:-days_out]\n",
    "    # test the model on the last N points of the data\n",
    "    test = stationary_series[-days_out:]\n",
    "    #\n",
    "    history = [x for x in train]\n",
    "\n",
    "    train.dropna(inplace=True)\n",
    "    test.dropna(inplace=True)\n",
    "    predicted_values = []\n",
    "    tested = []\n",
    "    \n",
    "    #1. Plug the noise into the model\n",
    "    #2. Train the model on the history of the noise\n",
    "    #3. Predict the noise of the next day\n",
    "    #4. Plug the next day's predicted noise into the signal function.\n",
    "    #5. Add the actual price of the next day to the price data set, transform it into stationarity and start again at step 1.\n",
    "    \n",
    "    for i in range(len(test)):\n",
    "        model = ARIMA(history, order=parameters)\n",
    "        model_fit = model.fit(disp=0)\n",
    "        yhat = float(model_fit.forecast(steps=1)[0])\n",
    "        predicted_values.append(yhat)\n",
    "        tested_values = list(test)[i]\n",
    "        tested.append(tested_values)\n",
    "        history.append(tested_values)\n",
    "    predictions_series = pd.Series(predicted_values, index = test.index)\n",
    "    \n",
    "    # This part couples the signal to the noise.\n",
    "    a = original_series.loc[original_series.index[-(days_out+1):]]['Price']\n",
    "    b = np.exp(predictions_series)\n",
    "    full_predictions = pd.DataFrame(a*b,columns=['Predicted with ARIMA']).dropna()\n",
    "    df = pd.concat([original_series.loc[original_series.index[-days_out:]],full_predictions],axis=1)\n",
    "    error = str(np.sqrt(mean_squared_error(df['Price'],df['Predicted with ARIMA'])))\n",
    "    print(\"ARIMA Root Mean Squared Error: \",error)\n",
    "    df.index.name = None\n",
    "    df[['Price','Predicted with ARIMA']] = df[['Price','Predicted with ARIMA']].apply(lambda x: round(x,2))\n",
    "    return df\n",
    "\n",
    "\n",
    "print(\"ARIMA bitcoin predictions\")\n",
    "bitcoin_ARIMA = ARIMA_predictions(bitcoin,bits_log_shift,(0,1,1),7)\n",
    "bitcoin_ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural net system was based upon sequential, dense LSTM modelling techniques. Like the ARIMA model, it was dependent upon a stationary time series input, modeling the noise and then putting the noise predictions back into the signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bitcoin Neural Net Predictions\n",
      "Neural Net Root Mean Squared Error:  49.40448539455479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Predicted with Neural Nets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>4318.35</td>\n",
       "      <td>4369.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>4364.41</td>\n",
       "      <td>4423.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>4352.30</td>\n",
       "      <td>4397.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>4345.75</td>\n",
       "      <td>4384.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>4390.31</td>\n",
       "      <td>4430.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>4597.31</td>\n",
       "      <td>4643.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>4583.02</td>\n",
       "      <td>4643.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price  Predicted with Neural Nets\n",
       "2017-08-23  4318.35                     4369.75\n",
       "2017-08-24  4364.41                     4423.16\n",
       "2017-08-25  4352.30                     4397.79\n",
       "2017-08-26  4345.75                     4384.69\n",
       "2017-08-27  4390.31                     4430.15\n",
       "2017-08-28  4597.31                     4643.98\n",
       "2017-08-29  4583.02                     4643.36"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "\n",
    "def Neural_Net_predictions(original_time_series, stationary_time_series, days_out,nb_epoch,neurons):\n",
    "    # note all these \"sub\" functions are used on the stationary time series.\n",
    "    # The neural nets are used to predict the noise. Once the noise is predicted\n",
    "    # Its plugged back into the signal\n",
    "    \n",
    "    X = stationary_time_series\n",
    "    \n",
    "    # Step 2\n",
    "    # Break the time series into shifted components. Each column is a shifted value \n",
    "    # previously in the time series\n",
    "    def timeseries_to_supervised(data, lag=1):\n",
    "        df = pd.DataFrame(data)\n",
    "        columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "        columns.append(df)\n",
    "        df = pd.concat(columns, axis=1)\n",
    "        df.fillna(0, inplace=True)\n",
    "        return df\n",
    "    \n",
    "    # Step 3\n",
    "    # We must put the time series onto the scale acceptable by the activation functions\n",
    "    def scale(train, test):\n",
    "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "        scaler = scaler.fit(train)\n",
    "        train = train.reshape(train.shape[0],train.shape[1])\n",
    "        train_scaled = scaler.transform(train)\n",
    "        test = test.reshape(test.shape[0],test.shape[1])\n",
    "        test_scaled = scaler.transform(test)\n",
    "        return scaler, train_scaled, test_scaled\n",
    "    \n",
    "    \n",
    "    # Step 4\n",
    "    def fit_lstm(train, batch_size, nb_epoch, neurons):\n",
    "        X, y = train[:, 0:-1], train[:, -1]\n",
    "        X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        for i in range(nb_epoch):\n",
    "            model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "            model.reset_states()\n",
    "        return model\n",
    "\n",
    "    \n",
    "    # Step 5\n",
    "    def forecast_lstm(model, batch_size, X):\n",
    "        X = X.reshape(1, 1, len(X))\n",
    "        yhat = model.predict(X, batch_size=batch_size)\n",
    "        return yhat[0,0]\n",
    "    \n",
    "    #Step 6\n",
    "    def invert_scale(scaler, X, value):\n",
    "        new_row = [x for x in X] + [value]\n",
    "        array = np.array(new_row)\n",
    "        array = array.reshape(1, len(array))\n",
    "        inverted = scaler.inverse_transform(array)\n",
    "        return inverted[0, -1]\n",
    "\n",
    "    # Now use all the above functions\n",
    "    supervised = timeseries_to_supervised(X,1)\n",
    "    supervised_values = supervised.values\n",
    "    train, test = supervised_values[0:-days_out], supervised_values[-days_out:]\n",
    "    scaler, train_scaled, test_scaled = scale(train, test)\n",
    "    train_reshaped = train_scaled[:,0].reshape(len(train_scaled),1,1)\n",
    "    lstm_model = fit_lstm(train_scaled,1,nb_epoch,neurons)\n",
    "    \n",
    "    #Step 7\n",
    "    predictions = []\n",
    "    for i in range(len(test_scaled)):\n",
    "        #Make one step forecast\n",
    "        X, y = test_scaled[i,0:-1], test_scaled[i,-1]\n",
    "        yhat = forecast_lstm(lstm_model,1,X)\n",
    "        #invert scaling\n",
    "        yhat = invert_scale(scaler, X, yhat)\n",
    "        #store forecast\n",
    "        predictions.append(yhat)\n",
    "    \n",
    "    # Step 8\n",
    "    # This part plugs it back into the signal\n",
    "    predictions_series = pd.Series(predictions, index = original_time_series.index[-days_out:])\n",
    "    a = original_time_series.loc[original_time_series.index[-(days_out+1):]]['Price']\n",
    "    b = np.exp(predictions_series)\n",
    "    full_predictions = pd.DataFrame(a*b,columns=['Predicted with Neural Nets']).dropna()\n",
    "    df = pd.concat([original_time_series.loc[original_time_series.index[-days_out:]],full_predictions],axis=1)\n",
    "    error = str(np.sqrt(mean_squared_error(df['Price'],df['Predicted with Neural Nets'])))\n",
    "    print(\"Neural Net Root Mean Squared Error: \",error)\n",
    "    df.index.name=None\n",
    "    df[['Price','Predicted with Neural Nets']] = df[['Price','Predicted with Neural Nets']].apply(lambda x: round(x,2))\n",
    "    return df\n",
    "\n",
    "print('Bitcoin Neural Net Predictions')\n",
    "bitcoin_NN = Neural_Net_predictions(bitcoin,bits_log_shift,days_out=7,nb_epoch=55,neurons=175)\n",
    "bitcoin_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
